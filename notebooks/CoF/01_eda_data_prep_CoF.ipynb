{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ba52e80",
   "metadata": {},
   "source": [
    "\n",
    "# 01 — EDA & Data Prep (CoF)\n",
    "\n",
    "Goals:\n",
    "- Load Line 10/20 raw data (CSV as configured)\n",
    "- Parse timestamps, sort, align by `machine_id`\n",
    "- Basic EDA (missingness, ranges, sampling frequency)\n",
    "- Build **Chance of Failure (CoF)** labels using the provided `breakdown` column (1 if breakdown event occurred)\n",
    "- Additionally compute **forward-looking** labels: CoF = 1 if any breakdown occurs within the next `horizon_minutes` (default: 30 min)\n",
    "- Save a clean, labeled snapshot to `data/processed/cof_labeled.parquet`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf775a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import sys, json, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "from datetime import timedelta\n",
    "\n",
    "# Paths\n",
    "NB_PATH = Path.cwd()\n",
    "ROOT = NB_PATH.parents[1] if NB_PATH.name.lower() == 'cof' else NB_PATH\n",
    "DATA_DIR = ROOT / 'data'\n",
    "RAW_DIR = DATA_DIR / 'raw'\n",
    "PROCESSED_DIR = DATA_DIR / 'processed'\n",
    "CONFIGS_DIR = ROOT / 'configs'\n",
    "\n",
    "for d in [DATA_DIR, RAW_DIR, PROCESSED_DIR, CONFIGS_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"ROOT:\", ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4ed6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Load configs\n",
    "def load_yaml(p):\n",
    "    import yaml, io\n",
    "    with open(p, 'r', encoding='utf-8') as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "base_cfg   = load_yaml(CONFIGS_DIR / 'base.yaml')\n",
    "task_cfg   = load_yaml(CONFIGS_DIR / 'task_cof.yaml')\n",
    "line10_cfg = load_yaml(CONFIGS_DIR / 'line10.yaml') if (CONFIGS_DIR / 'line10.yaml').exists() else None\n",
    "line20_cfg = load_yaml(CONFIGS_DIR / 'line20.yaml') if (CONFIGS_DIR / 'line20.yaml').exists() else None\n",
    "\n",
    "base_cfg, task_cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11d2ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Load raw data (CSV; adapt for SQL/Influx if needed)\n",
    "def load_raw_from_cfg(line_cfg: dict) -> pd.DataFrame:\n",
    "    if line_cfg is None:\n",
    "        return pd.DataFrame()\n",
    "    src = line_cfg.get('source', 'csv')\n",
    "    path = line_cfg.get('path')\n",
    "    if src == 'csv' and path:\n",
    "        p = Path(path)\n",
    "        if p.exists():\n",
    "            df = pd.read_csv(p)\n",
    "            df['__line'] = line_cfg.get('line')\n",
    "            return df\n",
    "    print(\"WARN: Could not load\", line_cfg)\n",
    "    return pd.DataFrame()\n",
    "\n",
    "df10 = load_raw_from_cfg(line10_cfg)\n",
    "df20 = load_raw_from_cfg(line20_cfg)\n",
    "\n",
    "df = pd.concat([df10, df20], ignore_index=True) if not df10.empty or not df20.empty else df10.copy()\n",
    "print(\"Shapes -> L10:\", df10.shape, \"| L20:\", df20.shape, \"| Combined:\", df.shape)\n",
    "display(df.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72072d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Standardize columns\n",
    "time_col = base_cfg.get('time_index', 'timestamp')\n",
    "id_col   = base_cfg.get('id_col', 'machine_id')\n",
    "\n",
    "# Try to infer timestamp if not present\n",
    "if time_col not in df.columns:\n",
    "    for cand in ['timestamp','time','datetime','DateTime','ts','date']:\n",
    "        if cand in df.columns:\n",
    "            time_col = cand\n",
    "            break\n",
    "\n",
    "# Try to infer id if not present\n",
    "if id_col not in df.columns:\n",
    "    for cand in ['machine_id','machine','asset_id','AssetID','line_id']:\n",
    "        if cand in df.columns:\n",
    "            id_col = cand\n",
    "            break\n",
    "\n",
    "print(\"Using time_col:\", time_col, \"| id_col:\", id_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85e17c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Parse timestamp & sort\n",
    "df[time_col] = pd.to_datetime(df[time_col], errors='coerce', utc=True)\n",
    "df = df.dropna(subset=[time_col]).sort_values([id_col, time_col]).reset_index(drop=True)\n",
    "\n",
    "# Ensure breakdown column exists\n",
    "breakdown_col = None\n",
    "for c in df.columns:\n",
    "    if c.lower() in {'breakdown','failure','fail','is_failure'}:\n",
    "        breakdown_col = c\n",
    "        break\n",
    "\n",
    "if breakdown_col is None:\n",
    "    raise ValueError(\"No breakdown/failure column found. Please ensure your file has a column named 'breakdown' (0/1).\")\n",
    "else:\n",
    "    # Normalize breakdown to 0/1 int\n",
    "    df[breakdown_col] = (df[breakdown_col].astype(str).isin(['1','True','true'])).astype(int)\n",
    "\n",
    "print(\"Breakdown column:\", breakdown_col, \"| Positive events:\", int(df[breakdown_col].sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b47a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Optional resampling to a fixed frequency\n",
    "freq = base_cfg.get('freq', None)  # e.g., '1min'\n",
    "if freq:\n",
    "    non_num = df.select_dtypes(exclude='number').columns.tolist()\n",
    "    non_num = list(dict.fromkeys([c for c in non_num if c not in [time_col]] + [id_col, '__line']))\n",
    "    num = df.select_dtypes(include='number').columns.tolist()\n",
    "    num = [c for c in num if c not in [id_col] and c != '__line']\n",
    "\n",
    "    out_frames = []\n",
    "    for gid, g in df.groupby(id_col):\n",
    "        g = g.set_index(time_col).sort_index()\n",
    "        g_num = g[num].resample(freq).mean()\n",
    "        g_non = g[non_num].resample(freq).ffill().bfill()\n",
    "        # For breakdown: any event in the interval → 1\n",
    "        if breakdown_col in g:\n",
    "            g_bd = g[[breakdown_col]].resample(freq).max()\n",
    "            g_num[breakdown_col] = g_bd[breakdown_col]\n",
    "        g_ = pd.concat([g_non, g_num], axis=1)\n",
    "        g_[id_col] = gid\n",
    "        out_frames.append(g_.reset_index())\n",
    "\n",
    "    df = pd.concat(out_frames, ignore_index=True).sort_values([id_col, time_col]).reset_index(drop=True)\n",
    "\n",
    "print(\"After optional resample:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e39e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Build CoF label (future breakdown within horizon)\n",
    "horizon_minutes = 30  # <=== adjust as needed\n",
    "def label_future_breakdown(g, time_col, breakdown_col, horizon_minutes=30):\n",
    "    times = g[time_col].values\n",
    "    bd = g[breakdown_col].values.astype(int)\n",
    "    out = np.zeros(len(g), dtype=int)\n",
    "    for i in range(len(g)):\n",
    "        t0 = times[i]\n",
    "        j = i + 1\n",
    "        while j < len(g) and (times[j] - t0) <= np.timedelta64(horizon_minutes, 'm'):\n",
    "            if bd[j] == 1:\n",
    "                out[i] = 1\n",
    "                break\n",
    "            j += 1\n",
    "    return out\n",
    "\n",
    "df['CoF'] = (\n",
    "    df.groupby(id_col, group_keys=False)\n",
    "      .apply(lambda g: pd.Series(label_future_breakdown(g, time_col, breakdown_col, horizon_minutes), index=g.index))\n",
    "      .astype(int)\n",
    ")\n",
    "\n",
    "print(\"CoF positives (within next\", horizon_minutes, \"min):\", int(df['CoF'].sum()))\n",
    "display(df[[id_col, time_col, breakdown_col, 'CoF']].head(12))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552fbe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Save snapshot\n",
    "out_path = PROCESSED_DIR / 'cof_labeled.parquet'\n",
    "df.to_parquet(out_path, index=False)\n",
    "print(\"Saved:\", out_path, \"| shape:\", df.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
