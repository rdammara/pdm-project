{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14d81fd7",
   "metadata": {},
   "source": [
    "\n",
    "# 03 — Train & Evaluate (RUL)\n",
    "\n",
    "Supports three algorithms via a parameter:\n",
    "- `algo = \"xgboost\"` (tabular)\n",
    "- `algo = \"lstm\"` (sequence)\n",
    "- `algo = \"cnn\"` (sequence)\n",
    "\n",
    "This notebook will:\n",
    "- Load processed features & labels\n",
    "- For sequence models, windowize the time-series\n",
    "- Train the model and compute metrics: RMSE, MAE, R², NASA Score, Silhouette Coefficient\n",
    "- Log results to `experiments/RUL/runs.csv` using `log_run(...)`\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1905b839",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import json, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Paths\n",
    "NB_PATH = Path.cwd()\n",
    "ROOT = NB_PATH.parents[1] if NB_PATH.name.lower() == 'rul' else NB_PATH\n",
    "DATA_DIR = ROOT / 'data'\n",
    "PROCESSED_DIR = DATA_DIR / 'processed'\n",
    "EXPERIMENTS_DIR = ROOT / 'experiments' / 'RUL'\n",
    "\n",
    "# Load datasets\n",
    "Xtr = pd.read_parquet(PROCESSED_DIR / 'RUL_X_train.parquet')\n",
    "Xva = pd.read_parquet(PROCESSED_DIR / 'RUL_X_val.parquet')\n",
    "Xte = pd.read_parquet(PROCESSED_DIR / 'RUL_X_test.parquet')\n",
    "\n",
    "ytr = pd.read_parquet(PROCESSED_DIR / 'RUL_y_train.parquet')['RUL'].values\n",
    "yva = pd.read_parquet(PROCESSED_DIR / 'RUL_y_val.parquet')['RUL'].values\n",
    "yte = pd.read_parquet(PROCESSED_DIR / 'RUL_y_test.parquet')['RUL'].values\n",
    "\n",
    "print(\"Loaded shapes:\",\n",
    "      Xtr.shape, Xva.shape, Xte.shape, \"|\",\n",
    "      ytr.shape, yva.shape, yte.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9107492",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Choose algorithm here\n",
    "algo = \"xgboost\"   # one of: \"xgboost\", \"lstm\", \"cnn\"\n",
    "random_seed = 42\n",
    "window = 20        # for sequence models\n",
    "stride = 1\n",
    "id_col, time_col = 'machine_id','timestamp'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd87a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Metrics\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "def nasa_score(y_true, y_pred, c=10.0):\n",
    "    # Penalty for underestimation heavier than overestimation\n",
    "    e = y_pred - y_true\n",
    "    over = e >= 0\n",
    "    under = ~over\n",
    "    s = np.zeros_like(e, dtype=float)\n",
    "    s[over]  = np.exp(-e[over] / c) - 1.0\n",
    "    s[under] = np.exp(e[under] / c) - 1.0\n",
    "    return float(np.mean(s**2))\n",
    "\n",
    "def compute_metrics(y_true, y_pred, X_for_sil=None):\n",
    "    rmse = math.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae  = mean_absolute_error(y_true, y_pred)\n",
    "    r2   = r2_score(y_true, y_pred)\n",
    "    nasa = nasa_score(y_true, y_pred)\n",
    "    # Silhouette: treat residuals as cluster structure vs. 0; use features if available\n",
    "    sil = np.nan\n",
    "    try:\n",
    "        if X_for_sil is not None and len(np.unique(y_true)) > 1:\n",
    "            # crude: bin true RUL into 3 groups for silhouette\n",
    "            bins = np.quantile(y_true, [0.33, 0.66])\n",
    "            labels = np.digitize(y_true, bins)\n",
    "            sil = silhouette_score(X_for_sil, labels)\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    return {'rmse': rmse, 'mae': mae, 'r2': r2, 'nasa': nasa, 'silhouette': sil}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99507827",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Helper: sequence windowing per machine (avoid leakage)\n",
    "def build_windows(X, y, window=20, stride=1, id_col='machine_id'):\n",
    "    feats = [c for c in X.columns if c not in [id_col, 'timestamp','__line']]\n",
    "    Xs, ys = [], []\n",
    "    for gid, gX in X.groupby(id_col):\n",
    "        idx = gX.index.values\n",
    "        for start in range(0, len(gX) - window + 1, stride):\n",
    "            end = start + window\n",
    "            sl = gX.iloc[start:end]\n",
    "            Xs.append(sl[feats].values)  # (window, features)\n",
    "            ys.append(y[idx[end-1]])     # predict RUL at window end\n",
    "    Xs = np.stack(Xs, axis=0) if Xs else np.empty((0, window, len(feats)))\n",
    "    ys = np.array(ys)\n",
    "    return Xs, ys, feats\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7822cc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Train/Eval by algo\n",
    "results = {}\n",
    "if algo == \"xgboost\":\n",
    "    # Tabular: just use the last value alignment already baked into X\n",
    "    import xgboost as xgb\n",
    "    feats = [c for c in Xtr.columns if c not in [id_col,'timestamp','__line']]\n",
    "    model = xgb.XGBRegressor(\n",
    "        n_estimators=500, max_depth=6, learning_rate=0.05,\n",
    "        subsample=0.9, colsample_bytree=0.9, random_state=random_seed, n_jobs=-1\n",
    "    )\n",
    "    model.fit(Xtr[feats], ytr, eval_set=[(Xva[feats], yva)], verbose=False)\n",
    "    pred = model.predict(Xte[feats])\n",
    "    results['pred'] = pred\n",
    "    results['feats'] = feats\n",
    "\n",
    "elif algo == \"lstm\":\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    Xtr_w, ytr_w, feats = build_windows(Xtr, ytr, window=window, stride=stride, id_col=id_col)\n",
    "    Xva_w, yva_w, _    = build_windows(Xva, yva, window=window, stride=stride, id_col=id_col)\n",
    "    Xte_w, yte_w, _    = build_windows(Xte, yte, window=window, stride=stride, id_col=id_col)\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Input(shape=(window, len(feats))),\n",
    "        keras.layers.LSTM(64, return_sequences=False),\n",
    "        keras.layers.Dense(64, activation='relu'),\n",
    "        keras.layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=keras.optimizers.Adam(1e-3), loss='mse')\n",
    "    model.fit(Xtr_w, ytr_w, validation_data=(Xva_w, yva_w), epochs=20, batch_size=128, verbose=1)\n",
    "    pred = model.predict(Xte_w).ravel()\n",
    "    results['pred'] = pred\n",
    "    results['feats'] = feats\n",
    "\n",
    "elif algo == \"cnn\":\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    Xtr_w, ytr_w, feats = build_windows(Xtr, ytr, window=window, stride=stride, id_col=id_col)\n",
    "    Xva_w, yva_w, _    = build_windows(Xva, yva, window=window, stride=stride, id_col=id_col)\n",
    "    Xte_w, yte_w, _    = build_windows(Xte, yte, window=window, stride=stride, id_col=id_col)\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Input(shape=(window, len(feats))),\n",
    "        keras.layers.Conv1D(64, kernel_size=3, padding='same', activation='relu'),\n",
    "        keras.layers.Conv1D(64, kernel_size=3, padding='same', activation='relu'),\n",
    "        keras.layers.GlobalAveragePooling1D(),\n",
    "        keras.layers.Dense(64, activation='relu'),\n",
    "        keras.layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=keras.optimizers.Adam(1e-3), loss='mse')\n",
    "    model.fit(Xtr_w, ytr_w, validation_data=(Xva_w, yva_w), epochs=20, batch_size=128, verbose=1)\n",
    "    pred = model.predict(Xte_w).ravel()\n",
    "    results['pred'] = pred\n",
    "    results['feats'] = feats\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"Unknown algo. Use one of: xgboost, lstm, cnn\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee3e680",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Evaluate & log\n",
    "from math import sqrt\n",
    "import json\n",
    "metrics = {}\n",
    "if algo in {\"lstm\",\"cnn\"}:\n",
    "    # yte_w aligned inside windowing call\n",
    "    # Recompute to get yte_w for metrics\n",
    "    _, _, feats = results['feats'], results['feats'], results['feats']\n",
    "    # quick rebuild to get ground-truth aligned with pred\n",
    "    Xte_w, yte_w, _ = build_windows(Xte, yte, window=window, stride=stride, id_col=id_col)\n",
    "    y_true = yte_w\n",
    "else:\n",
    "    y_true = yte\n",
    "\n",
    "y_pred = results['pred']\n",
    "m = compute_metrics(y_true, y_pred, X_for_sil=None)\n",
    "m\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78ecde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Log to experiments/RUL/runs.csv\n",
    "import pandas as pd, json\n",
    "from datetime import datetime\n",
    "runs_csv = EXPERIMENTS_DIR / 'runs.csv'\n",
    "if not runs_csv.exists():\n",
    "    pd.DataFrame(columns=[\n",
    "        'timestamp','task','algo','line','seed','params_json',\n",
    "        'rmse','mae','r2','nasa','silhouette','dataset_hash','notes','artifact_dir'\n",
    "    ]).to_csv(runs_csv, index=False)\n",
    "\n",
    "row = {\n",
    "    'timestamp': datetime.utcnow().isoformat(),\n",
    "    'task': 'RUL',\n",
    "    'algo': algo,\n",
    "    'line': -1,                 # set if training per-line\n",
    "    'seed': 42,\n",
    "    'params_json': json.dumps({'algo': algo, 'window': int(window)}),\n",
    "    'rmse': m.get('rmse'),\n",
    "    'mae': m.get('mae'),\n",
    "    'r2': m.get('r2'),\n",
    "    'nasa': m.get('nasa'),\n",
    "    'silhouette': m.get('silhouette'),\n",
    "    'dataset_hash': '',\n",
    "    'notes': '',\n",
    "    'artifact_dir': ''\n",
    "}\n",
    "df_runs = pd.read_csv(runs_csv)\n",
    "df_runs = pd.concat([df_runs, pd.DataFrame([row])], ignore_index=True)\n",
    "df_runs.to_csv(runs_csv, index=False)\n",
    "print(\"Logged:\", runs_csv)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
