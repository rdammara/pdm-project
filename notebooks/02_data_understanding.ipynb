{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Data Understanding\n",
    "\n",
    "**CRISP-DM Phase 2: Data Understanding**\n",
    "\n",
    "This notebook explores the sensor data, failure events, and data quality for the predictive maintenance project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'src'))\n",
    "\n",
    "from data_extraction.sql_extractor import SQLExtractor\n",
    "from utils.helpers import load_config, setup_logging\n",
    "\n",
    "# Setup\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Logging\n",
    "logger = setup_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Extraction\n",
    "\n",
    "Extract data from SQL Server database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SQL extractor\n",
    "# Note: Ensure database_config.yaml is configured with your credentials\n",
    "\n",
    "# For demo purposes, we'll assume data is already extracted\n",
    "# Uncomment below to extract from SQL Server:\n",
    "\n",
    "# with SQLExtractor('config/database_config.yaml') as extractor:\n",
    "#     sensor_data = extractor.extract_sensor_data(\n",
    "#         start_date='2023-01-01',\n",
    "#         end_date='2023-12-31',\n",
    "#         output_path='data/raw/sensor_data.csv'\n",
    "#     )\n",
    "#     \n",
    "#     failure_events = extractor.extract_failure_events(\n",
    "#         start_date='2023-01-01',\n",
    "#         end_date='2023-12-31',\n",
    "#         output_path='data/raw/failure_events.csv'\n",
    "#     )\n",
    "\n",
    "# For demo, load from files if they exist\n",
    "# sensor_data = pd.read_csv('data/raw/sensor_data.csv')\n",
    "# failure_events = pd.read_csv('data/raw/failure_events.csv')\n",
    "\n",
    "print(\"Data extraction completed (or load existing files).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initial Data Exploration\n",
    "\n",
    "Explore basic statistics and structure of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sensor data info\n",
    "# print(\"Sensor Data Info:\")\n",
    "# print(sensor_data.info())\n",
    "# print(\"\\nFirst few rows:\")\n",
    "# sensor_data.head()\n",
    "\n",
    "print(\"Placeholder: Display sensor data summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display failure events info\n",
    "# print(\"Failure Events Info:\")\n",
    "# print(failure_events.info())\n",
    "# print(\"\\nFirst few rows:\")\n",
    "# failure_events.head()\n",
    "\n",
    "print(\"Placeholder: Display failure events summary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "# missing_data = sensor_data.isnull().sum()\n",
    "# print(\"Missing values per column:\")\n",
    "# print(missing_data[missing_data > 0])\n",
    "\n",
    "# Visualize missing data\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# sns.heatmap(sensor_data.isnull(), cbar=False, yticklabels=False)\n",
    "# plt.title('Missing Data Heatmap')\n",
    "# plt.show()\n",
    "\n",
    "print(\"Placeholder: Check for missing values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sensor Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sensor distributions\n",
    "# sensor_cols = [col for col in sensor_data.columns if 'sensor' in col.lower()]\n",
    "# \n",
    "# fig, axes = plt.subplots(len(sensor_cols), 1, figsize=(12, 4*len(sensor_cols)))\n",
    "# for idx, col in enumerate(sensor_cols):\n",
    "#     sensor_data[col].hist(bins=50, ax=axes[idx])\n",
    "#     axes[idx].set_title(f'{col} Distribution')\n",
    "#     axes[idx].set_xlabel(col)\n",
    "#     axes[idx].set_ylabel('Frequency')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "print(\"Placeholder: Plot sensor distributions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Failure Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze failure frequency\n",
    "# failure_counts = failure_events.groupby('machine_id').size()\n",
    "# print(f\"Total machines: {len(failure_counts)}\")\n",
    "# print(f\"Total failures: {failure_counts.sum()}\")\n",
    "# print(f\"Failures per machine (mean): {failure_counts.mean():.2f}\")\n",
    "\n",
    "# Plot failure distribution\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# failure_counts.hist(bins=20)\n",
    "# plt.title('Distribution of Failures per Machine')\n",
    "# plt.xlabel('Number of Failures')\n",
    "# plt.ylabel('Number of Machines')\n",
    "# plt.show()\n",
    "\n",
    "print(\"Placeholder: Analyze failure patterns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Time Series Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sensor readings over time for a sample machine\n",
    "# sample_machine = sensor_data['machine_id'].iloc[0]\n",
    "# machine_data = sensor_data[sensor_data['machine_id'] == sample_machine].head(1000)\n",
    "\n",
    "# sensor_cols = [col for col in machine_data.columns if 'sensor' in col.lower()]\n",
    "# fig, axes = plt.subplots(len(sensor_cols), 1, figsize=(14, 3*len(sensor_cols)))\n",
    "# for idx, col in enumerate(sensor_cols):\n",
    "#     axes[idx].plot(machine_data['timestamp'], machine_data[col])\n",
    "#     axes[idx].set_title(f'{col} Over Time (Machine {sample_machine})')\n",
    "#     axes[idx].set_xlabel('Timestamp')\n",
    "#     axes[idx].set_ylabel(col)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "print(\"Placeholder: Plot time series patterns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary and Findings\n",
    "\n",
    "Document key findings:\n",
    "- Data quality issues identified\n",
    "- Sensor value ranges and distributions\n",
    "- Failure frequency and patterns\n",
    "- Temporal patterns in sensor data\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Proceed to **03 - Data Preparation** to:\n",
    "1. Clean and preprocess data\n",
    "2. Compute RUL labels\n",
    "3. Engineer features from time-series data\n",
    "4. Prepare train/validation/test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
