{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Data Preparation\n",
    "\n",
    "**CRISP-DM Phase 3: Data Preparation**\n",
    "\n",
    "This notebook covers data cleaning, RUL labeling, and feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'src'))\n",
    "\n",
    "from data_processing.rul_calculator import RULCalculator\n",
    "from data_processing.event_labeler import EventLabeler\n",
    "from feature_engineering.time_series_features import TimeSeriesFeatureGenerator\n",
    "from feature_engineering.statistical_features import StatisticalFeatureGenerator\n",
    "from utils.helpers import load_config, handle_missing_values, save_dataframe\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "config = load_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "# sensor_data = pd.read_csv('data/raw/sensor_data.csv')\n",
    "# failure_events = pd.read_csv('data/raw/failure_events.csv')\n",
    "\n",
    "print(\"Placeholder: Load raw data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "# strategy = config['data_processing']['missing_value_strategy']\n",
    "# sensor_data = handle_missing_values(sensor_data, strategy=strategy)\n",
    "\n",
    "# Convert timestamps\n",
    "# sensor_data['timestamp'] = pd.to_datetime(sensor_data['timestamp'])\n",
    "# failure_events['failure_timestamp'] = pd.to_datetime(failure_events['failure_timestamp'])\n",
    "\n",
    "print(\"Placeholder: Clean data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. RUL Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize RUL calculator\n",
    "# clip_max = config['data_processing']['rul_clip_max']\n",
    "# rul_calc = RULCalculator(clip_max=clip_max)\n",
    "\n",
    "# Compute RUL\n",
    "# sensor_data = rul_calc.compute_rul(\n",
    "#     sensor_data,\n",
    "#     failure_events,\n",
    "#     time_unit='hours'\n",
    "# )\n",
    "\n",
    "# Display RUL distribution\n",
    "# sensor_data['RUL'].hist(bins=50, figsize=(10, 6))\n",
    "# plt.title('RUL Distribution')\n",
    "# plt.xlabel('RUL (hours)')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.show()\n",
    "\n",
    "print(\"Placeholder: Calculate RUL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Failure Labeling for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize event labeler\n",
    "# horizon_days = config['modeling']['failure_classification']['prediction_horizon_days']\n",
    "# labeler = EventLabeler(prediction_horizon=horizon_days, time_unit='days')\n",
    "\n",
    "# Label failure windows\n",
    "# sensor_data = labeler.label_failure_window(sensor_data, failure_events)\n",
    "\n",
    "# Check class balance\n",
    "# print(\"Class distribution:\")\n",
    "# print(sensor_data['failure_label'].value_counts())\n",
    "# print(f\"\\nPositive class ratio: {sensor_data['failure_label'].mean():.4f}\")\n",
    "\n",
    "print(\"Placeholder: Label failure windows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize feature generators\n",
    "# window_sizes = config['feature_engineering']['rolling_windows']\n",
    "# lag_sizes = config['feature_engineering']['lag_features']\n",
    "\n",
    "# ts_generator = TimeSeriesFeatureGenerator(window_sizes=window_sizes, lag_sizes=lag_sizes)\n",
    "# stat_generator = StatisticalFeatureGenerator()\n",
    "\n",
    "# Generate time-series features\n",
    "# sensor_data = ts_generator.generate_features(sensor_data)\n",
    "# print(f\"After time-series features: {sensor_data.shape}\")\n",
    "\n",
    "# Generate statistical features\n",
    "# sensor_data = stat_generator.generate_features(sensor_data)\n",
    "# print(f\"After statistical features: {sensor_data.shape}\")\n",
    "\n",
    "print(\"Placeholder: Generate features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train/Validation/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data\n",
    "# test_size = config['data_processing']['test_size']\n",
    "# val_size = config['data_processing']['validation_size']\n",
    "\n",
    "# train_val, test = train_test_split(sensor_data, test_size=test_size, random_state=42)\n",
    "# train, val = train_test_split(train_val, test_size=val_size/(1-test_size), random_state=42)\n",
    "\n",
    "# print(f\"Train size: {len(train)}\")\n",
    "# print(f\"Validation size: {len(val)}\")\n",
    "# print(f\"Test size: {len(test)}\")\n",
    "\n",
    "print(\"Placeholder: Split data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed data\n",
    "# save_dataframe(train, 'data/processed/train_data.csv')\n",
    "# save_dataframe(val, 'data/processed/val_data.csv')\n",
    "# save_dataframe(test, 'data/processed/test_data.csv')\n",
    "\n",
    "print(\"Placeholder: Save processed data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Proceed to **04 - Modeling** to train XGBoost models for RUL prediction and failure classification."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
